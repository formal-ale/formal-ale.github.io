<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <meta name="title" content="Formal Abductive Latent Explanations for Prototype-Based Networks">
  <meta name="description" content="We propose Abductive Latent Explanations (ALEs), a formalism to express sufficient conditions on the intermediate representation of an instance that imply the prediction.">
  <meta name="keywords" content="Explainable AI, Prototype-based Networks, Abductive Reasoning, Formal Verification, Machine Learning, Computer Vision">
  <meta name="author" content="Jules Soria, Zakaria Chihani, Julien Girard-Satabin, Alban Grastien, Romain Xu-Darme, Daniela Cancila">
  <meta name="robots" content="index, follow">
  <meta name="language" content="English">
  
  <meta property="og:type" content="article">
  <meta property="og:site_name" content="Universit√© Paris-Saclay, CEA, List">
  <meta property="og:title" content="Formal Abductive Latent Explanations for Prototype-Based Networks">
  <meta property="og:description" content="We propose Abductive Latent Explanations (ALEs), a formalism to express sufficient conditions on the intermediate representation of an instance that imply the prediction.">
  <meta property="og:url" content="https://julsoria.github.io/ale/"> 
  <meta property="og:image" content="static/images/figure1_preview.png">
  <meta property="og:image:width" content="1200">
  <meta property="og:image:height" content="630">
  <meta property="og:image:alt" content="ALE Framework Overview">

  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:title" content="Formal Abductive Latent Explanations for Prototype-Based Networks">
  <meta name="twitter:description" content="Bridging the gap between FXAI and prototype-based learning with formal guarantees.">
  <meta name="twitter:image" content="static/images/figure1_preview.png">

  <meta name="citation_title" content="Formal Abductive Latent Explanations for Prototype-Based Networks">
  <meta name="citation_author" content="Soria, Jules">
  <meta name="citation_author" content="Chihani, Zakaria">
  <meta name="citation_author" content="Girard-Satabin, Julien">
  <meta name="citation_author" content="Grastien, Alban">
  <meta name="citation_author" content="Xu-Darme, Romain">
  <meta name="citation_author" content="Cancila, Daniela">
  <meta name="citation_publication_date" content="2026">
  <meta name="citation_conference_title" content="AAAI Conference on Artificial Intelligence">
  
  <title>Formal Abductive Latent Explanations for Prototype-Based Networks</title>
  
  <!-- <link rel="icon" type="image/x-icon" href="static/images/favicon.ico"> -->
  <link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üç∫</text></svg>">
  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/index.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700;800&display=swap" rel="stylesheet">
  
  <script defer src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script defer src="static/js/bulma-carousel.min.js"></script>
  <script defer src="static/js/bulma-slider.min.js"></script>
  <script defer src="static/js/index.js"></script>
  
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "ScholarlyArticle",
    "headline": "Formal Abductive Latent Explanations for Prototype-Based Networks",
    "author": [
      {"@type": "Person", "name": "Jules Soria"},
      {"@type": "Person", "name": "Zakaria Chihani"},
      {"@type": "Person", "name": "Julien Girard-Satabin"},
      {"@type": "Person", "name": "Alban Grastien"},
      {"@type": "Person", "name": "Romain Xu-Darme"},
      {"@type": "Person", "name": "Daniela Cancila"}
    ],
    "datePublished": "2026-01-01",
    "publisher": {"@type": "Organization", "name": "AAAI"},
    "keywords": ["XAI", "Formal Methods", "Prototype Networks", "Abductive Explanations"]
  }
  </script>
</head>
<body>

  <main id="main-content">
  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Formal Abductive Latent Explanations<br>for Prototype-Based Networks</h1>
            
            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <a href="#">Jules Soria</a>,</span>
              <span class="author-block">
                <a href="#">Zakaria Chihani</a>,</span>
              <span class="author-block">
                <a href="#">Julien Girard-Satabin</a>,</span>
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <a href="#">Alban Grastien</a>,</span>
              <span class="author-block">
                <a href="#">Romain Xu-Darme</a>,</span>
              <span class="author-block">
                <a href="#">Daniela Cancila</a></span>
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block">Universit√© Paris-Saclay, CEA, List, F-91120, Palaiseau, France</span>
            </div>

            <div class="is-size-5 publication-authors" style="margin-top: 10px; font-weight: bold;">
              <span class="author-block">AAAI 2026</span>
            </div>

            <div class="column has-text-centered">
              <div class="publication-links">
                <span class="link-block">
                  <a href="static/pdfs/paper.pdf" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon"><i class="fas fa-file-pdf"></i></span>
                  <span>Paper</span>
                  </a>
                </span>

                <span class="link-block">
                  <a href="https://github.com/julsoria/ale" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon"><i class="fab fa-github"></i></span>
                  <span>Code</span>
                  </a>
                </span>

                <span class="link-block">
                  <a href="https://arxiv.org/" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon"><i class="ai ai-arxiv"></i></span>
                  <span>arXiv</span>
                  </a>
                </span>

                <span class="link-block">
                  <a href="https://zenodo.org/" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon"><i class="ai ai-zenodo"></i></span>
                  <span>Zenodo</span>
                  </a>
                </span>
                
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="hero teaser">
    <div class="container is-max-desktop">
      <div class="hero-body">
        <div class="has-text-centered">
            <img src="static/images/figure1_teaser.png" 
                 alt="Figure 1: Example of a top-1 explanation for a ProtoPNet"
                 style="width: 100%; height: auto; max-width: 1000px; border-radius: 10px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);">
        </div>
        <h2 class="subtitle has-text-centered" style="margin-top: 15px;">
          <strong>Figure 1:</strong> Example of a top-1 explanation for a ProtoPNet with five prototypical parts for two classes.
          We propose <strong>ALEs</strong> to bridge the gap between Formal XAI and prototype-based learning.
        </h2>
      </div>
    </div>
  </section>

  <section class="section hero is-light">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <p>
              Case-based reasoning networks are machine-learning models that make predictions based on similarity between the input and prototypical parts of training samples, called prototypes. Such models are able to explain each decision by pointing to the prototypes that contributed the most to the final outcome. As the explanation is a core part of the prediction, they are often qualified as "interpretable by design".
            </p>
            <p>
              While promising, we show that such explanations are sometimes misleading, which hampers their usefulness in safety-critical contexts. In particular, several instances may lead to different predictions and yet have the same explanation. Drawing inspiration from the field of formal eXplainable AI (FXAI), we propose <strong>Abductive Latent Explanations (ALEs)</strong>, a formalism to express sufficient conditions on the intermediate (latent) representation of the instance that imply the prediction.
            </p>
            <p>
              Our approach combines the inherent interpretability of case-based reasoning models and the guarantees provided by formal XAI. We propose a solver-free and scalable algorithm for generating ALEs based on three distinct paradigms, compare them, and present the feasibility of our approach on diverse datasets for both standard and fine-grained image classification.
            </p>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="section" style="background-color: #f5f5f5;">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Methodology: Formal Guarantees in Latent Space</h2>
        <div class="content has-text-justified">
          <p>
            Standard Formal Explainable AI (FXAI) defines explanations as preconditions on the input space (pixels). 
            We introduce <strong>Abductive Latent Explanations (ALEs)</strong>, moving the formal guarantees to the latent space $\mathcal{Z}$. 
            Our framework proves that a subset of latent features is sufficient to entail the model's prediction, regardless of the unobserved features.
          </p>
        </div>
      </div>
    </div>

    <div class="columns is-centered">
      
      <div class="column is-4">
        <div class="box" style="height: 100%;">
          <div class="icon-box has-text-centered is-size-3 mb-3">
            <i class="fas fa-cube"></i>
          </div>
          <h4 class="title is-5 has-text-centered">1. Latent Definition</h4>
          <div class="content is-small">
            <p>
              An ALE is a subset of latent features $\mathcal{E} \subseteq P \times L$ that defines a precondition $\phi_{\mathcal{E}}$ on the latent representation.
            </p>
            <p>
              Unlike heuristic methods, we require <strong>Subset-Minimality</strong>: no proper subset of $\mathcal{E}$ can serve as a valid explanation. This ensures the explanation is both sufficient and compact.
            </p>
            <p class="is-italic has-text-grey">
              "Any image $x$ whose latent representation matches $\mathcal{E}$ will result in the same classification $c$."
            </p>
          </div>
        </div>
      </div>

      <div class="column is-4">
        <div class="box" style="height: 100%;">
          <div class="icon-box has-text-centered is-size-3 mb-3">
            <i class="fas fa-project-diagram"></i>
          </div>
          <h4 class="title is-5 has-text-centered">2. Constraint Propagation</h4>
          <div class="content is-small">
            <p>
              Since prototypes are fixed points in $\mathcal{Z}$, we can bound the activation scores of unobserved features using spatial geometry. We implement two paradigms:
            </p>
            <ul>
              <li>
                <strong>Triangle Inequality:</strong> We use the known distances between prototypes $d(p_i, p_j)$ to bound the similarity of any feature vector $z_l$ to all other prototypes.
              </li>
              <li>
                <strong>Hypersphere Intersection:</strong> We model the latent vector as the intersection of hyperspheres centered at prototypes, refining the radius of possible locations ($r_3$) to tighten the bounds on the activation space.
              </li>
            </ul>
          </div>
        </div>
      </div>

      <div class="column is-4">
        <div class="box" style="height: 100%;">
          <div class="icon-box has-text-centered is-size-3 mb-3">
            <i class="fas fa-check-double"></i>
          </div>
          <h4 class="title is-5 has-text-centered">3. Formal Verification</h4>
          <div class="content is-small">
            <p>
              We define a <strong>Constrained Activation Space</strong> $\alpha_{\mathcal{E}}$. To verify an explanation, we construct the <em>Maximally Class-Favoring Element</em> within these bounds.
            </p>
            <p>
              The explanation is valid if and only if the predicted class $c$ dominates all other classes $k$ even in the worst-case scenario within the bounds:
            </p>
            <div class="has-text-centered" style="background: #eee; padding: 5px; border-radius: 4px; margin: 10px 0;">
              $h_c(a^*) \ge h_k(a^*)$
            </div>
            <p>
              This solver-free approach avoids the NP-completeness of pixel-level proofs.
            </p>
          </div>
        </div>
      </div>
    </div>

    <div class="columns is-centered mt-5">
      <div class="column is-full-width has-text-centered">
        <img src="static/images/method_diagram.png" 
             alt="Hypersphere Intersection Approximation"
             style="max-width: 80%; border: 1px solid #dbdbdb; border-radius: 8px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);">
        <p class="is-size-7 mt-2">
          <strong>Figure 2:</strong> Visualization of the <em>Hypersphere Intersection Approximation</em> used to bound the latent space.
        </p>
      </div>
    </div>

  </div>
  </section>

  
  <section class="section" style="background-color: #f5f5f5;">
  <div class="container is-max-desktop">
    <h2 class="title is-3 has-text-centered">Visualizing the Latent Bounds</h2>
    <div class="content has-text-centered">
      <p>
        To certify an explanation without a solver, we must bound the location of the latent vector $z$.
        We compare our two paradigms below. The <strong>Hypersphere Intersection</strong> (Center) yields significantly 
        tighter bounds (blue dashed line) than the <strong>Triangle Inequality</strong> (Left), approximating the 
        true distances (Right) more accurately[cite: 197, 210].
      </p>
    </div>

    <div class="columns is-centered is-vcentered">
      
      <div class="column is-4 has-text-centered">
        <figure class="image">
          <img src="static/images/geometric_figure_triangle.png" 
               alt="Triangle Inequality Bounds" 
               style="border: 1px solid #bbb; border-radius: 5px; background: white;">
        </figure>
        <h4 class="subtitle is-6 mt-2">
          <strong>Paradigm 1:</strong><br>Triangle Inequality
        </h4>
        <p class="is-size-7">
          Loose bounds derived from distances between prototypes.<br>
          <em>Range: [0.656, 1.600]</em>
        </p>
      </div>

      <div class="column is-4 has-text-centered">
        <figure class="image">
          <img src="static/images/geometric_figure_intersection.png" 
               alt="Hypersphere Intersection Bounds" 
               style="border: 2px solid #209cee; border-radius: 5px; background: white; box-shadow: 0 0 10px rgba(32, 156, 238, 0.3);">
        </figure>
        <h4 class="subtitle is-6 mt-2">
          <strong>Paradigm 2:</strong><br>Hypersphere Intersection
        </h4>
        <p class="is-size-7">
          <strong>Ours.</strong> Tighter bounds by intersecting constraints.<br>
          <em>Range: [0.839, 1.368]</em>
        </p>
      </div>

      <div class="column is-4 has-text-centered">
        <figure class="image">
          <img src="static/images/geometric_figure_true.png" 
               alt="True Distances Ground Truth" 
               style="border: 1px solid #bbb; border-radius: 5px; background: white;">
        </figure>
        <h4 class="subtitle is-6 mt-2">
          Ground Truth
        </h4>
        <p class="is-size-7">
          Actual distances $d(P, z)$ and $d(P, z')$ in the latent space.<br>
          <em>Ref: 0.846 | 1.364</em>
        </p>
      </div>
      
    </div>
  </div>
  </section>

  <section class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-3 has-text-centered">Experimental Results</h2>
    <div class="content has-text-justified">
      <p>
        We evaluated our approach on diverse datasets (CIFAR-10, MNIST, Oxford Flowers, etc.). 
        The table below summarizes the average explanation sizes. Note that <strong>Hypersphere Intersection</strong> 
        frequently yields more compact explanations or tighter bounds compared to the top-k heuristic[cite: 289, 299].
      </p>
    </div>

    <div class="box">
      <figure class="image is-fullwidth">
        <img src="static/images/results_table.png" alt="Table 2: Summary of Average Explanation Sizes">
        <figcaption class="has-text-centered is-size-7 mt-2">
          <strong>Table 2:</strong> Summary of Average Explanation Sizes (Correct / Incorrect) for each dataset. 
          Best (smallest) results indicated in bold[cite: 282].
        </figcaption>
      </figure>
    </div>
  </div>
  </section>


  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <div class="bibtex-header">
        <h2 class="title">BibTeX</h2>
        <button class="copy-bibtex-btn" onclick="copyBibTeX()" title="Copy BibTeX to clipboard">
          <i class="fas fa-copy"></i>
          <span class="copy-text">Copy</span>
        </button>
      </div>
      <pre id="bibtex-code"><code>@inproceedings{soria2026formal,
  title={Formal Abductive Latent Explanations for Prototype-Based Networks},
  author={Soria, Jules and Chihani, Zakaria and Girard-Satabin, Julien and Grastien, Alban and Xu-Darme, Romain and Cancila, Daniela},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  year={2026},
  url={https://github.com/julsoria/ale}
}</code></pre>
    </div>
  </section>

  <section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Framework</h2>
        <div class="content has-text-justified">
          <p>
            Our models were trained using <strong>CaBRNet</strong> (Case-Based Reasoning Network), 
            an open-source library designed for developing and evaluating prototype-based models. 
            <!-- CaBRNet ensures that the underlying prototype layers and decision mechanisms adhere 
            strictly to the interpretable-by-design philosophy required for valid Abductive Latent Explanations. -->
          </p>
          <div class="has-text-centered">
            <a href="https://github.com/aiser-team/cabrnet" target="_blank" class="button is-dark is-rounded">
              <span class="icon"><i class="fab fa-github"></i></span>
              <span>View CaBRNet Repository</span>
            </a>
          </div>
        </div>
      </div>
    </div>
  </div>
  </section>


  <footer class="footer">
    <div class="container">
      <div class="content has-text-centered">
        <p>
          This website is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">Creative Commons Attribution-ShareAlike 4.0 International License</a>.
          Source code based on <a href="https://nerfies.github.io">Nerfies</a>.
        </p>
      </div>
    </div>
  </footer>

</body>
</html>