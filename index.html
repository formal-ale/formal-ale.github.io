<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <meta name="title" content="Formal Abductive Latent Explanations for Prototype-Based Networks">
  <meta name="description" content="We propose Abductive Latent Explanations (ALEs), a formalism to express sufficient conditions on the intermediate representation of an instance that imply the prediction.">
  <meta name="keywords" content="Explainable AI, Prototype-based Networks, Abductive Reasoning, Formal Verification, Machine Learning, Computer Vision">
  <meta name="author" content="Jules Soria, Zakaria Chihani, Julien Girard-Satabin, Alban Grastien, Romain Xu-Darme, Daniela Cancila">
  <meta name="robots" content="index, follow">
  <meta name="language" content="English">
  
  <meta property="og:type" content="article">
  <meta property="og:site_name" content="Université Paris-Saclay, CEA, List">
  <meta property="og:title" content="Formal Abductive Latent Explanations for Prototype-Based Networks">
  <meta property="og:description" content="We propose Abductive Latent Explanations (ALEs), a formalism to express sufficient conditions on the intermediate representation of an instance that imply the prediction.">
  <meta property="og:url" content="https://julsoria.github.io/ale/"> 
  <meta property="og:image" content="static/images/figure1_preview.png">
  <meta property="og:image:width" content="1200">
  <meta property="og:image:height" content="630">
  <meta property="og:image:alt" content="ALE Framework Overview">

  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:title" content="Formal Abductive Latent Explanations for Prototype-Based Networks">
  <meta name="twitter:description" content="Bridging the gap between FXAI and prototype-based learning with formal guarantees.">
  <meta name="twitter:image" content="static/images/figure1_preview.png">

  <meta name="citation_title" content="Formal Abductive Latent Explanations for Prototype-Based Networks">
  <meta name="citation_author" content="Soria, Jules">
  <meta name="citation_author" content="Chihani, Zakaria">
  <meta name="citation_author" content="Girard-Satabin, Julien">
  <meta name="citation_author" content="Grastien, Alban">
  <meta name="citation_author" content="Xu-Darme, Romain">
  <meta name="citation_author" content="Cancila, Daniela">
  <meta name="citation_publication_date" content="2026">
  <meta name="citation_conference_title" content="AAAI Conference on Artificial Intelligence">
  
  <title>Formal Abductive Latent Explanations for Prototype-Based Networks</title>
  
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/index.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700;800&display=swap" rel="stylesheet">
  
  <script defer src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script defer src="static/js/bulma-carousel.min.js"></script>
  <script defer src="static/js/bulma-slider.min.js"></script>
  <script defer src="static/js/index.js"></script>
  
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "ScholarlyArticle",
    "headline": "Formal Abductive Latent Explanations for Prototype-Based Networks",
    "author": [
      {"@type": "Person", "name": "Jules Soria"},
      {"@type": "Person", "name": "Zakaria Chihani"},
      {"@type": "Person", "name": "Julien Girard-Satabin"},
      {"@type": "Person", "name": "Alban Grastien"},
      {"@type": "Person", "name": "Romain Xu-Darme"},
      {"@type": "Person", "name": "Daniela Cancila"}
    ],
    "datePublished": "2026-01-01",
    "publisher": {"@type": "Organization", "name": "AAAI"},
    "keywords": ["XAI", "Formal Methods", "Prototype Networks", "Abductive Explanations"]
  }
  </script>
</head>
<body>

  <main id="main-content">
  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Formal Abductive Latent Explanations<br>for Prototype-Based Networks</h1>
            
            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <a href="#">Jules Soria</a>,</span>
              <span class="author-block">
                <a href="#">Zakaria Chihani</a>,</span>
              <span class="author-block">
                <a href="#">Julien Girard-Satabin</a>,</span>
              <span class="author-block">
                <a href="#">Alban Grastien</a>,</span>
              <span class="author-block">
                <a href="#">Romain Xu-Darme</a>,</span>
              <span class="author-block">
                <a href="#">Daniela Cancila</a></span>
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block">Université Paris-Saclay, CEA, List, F-91120, Palaiseau, France</span>
              <span class="author-block"><br>AAAI 2026</span>
            </div>

            <div class="column has-text-centered">
              <div class="publication-links">
                <span class="link-block">
                  <a href="static/pdfs/paper.pdf" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon"><i class="fas fa-file-pdf"></i></span>
                  <span>Paper</span>
                  </a>
                </span>

                <span class="link-block">
                  <a href="https://github.com/julsoria/ale" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon"><i class="fab fa-github"></i></span>
                  <span>Code</span>
                  </a>
                </span>

                <span class="link-block">
                  <a href="https://arxiv.org/" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon"><i class="ai ai-arxiv"></i></span>
                  <span>arXiv</span>
                  </a>
                </span>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="hero teaser">
    <div class="container is-max-desktop">
      <div class="hero-body">
        <figure class="image is-16by9">
            <img src="static/images/figure1_teaser.png" alt="Figure 1: Example of a top-1 explanation for a ProtoPNet">
        </figure>
        <h2 class="subtitle has-text-centered">
          <strong>Figure 1:</strong> Example of a top-1 explanation for a ProtoPNet with five prototypical parts for two classes. 
          We propose <strong>ALEs</strong> to bridge the gap between Formal XAI and prototype-based learning.
        </h2>
      </div>
    </div>
  </section>

  <section class="section hero is-light">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <p>
              Case-based reasoning networks are machine-learning models that make predictions based on similarity between the input and prototypical parts of training samples, called prototypes. Such models are able to explain each decision by pointing to the prototypes that contributed the most to the final outcome. As the explanation is a core part of the prediction, they are often qualified as "interpretable by design".
            </p>
            <p>
              While promising, we show that such explanations are sometimes misleading, which hampers their usefulness in safety-critical contexts. In particular, several instances may lead to different predictions and yet have the same explanation. Drawing inspiration from the field of formal eXplainable AI (FXAI), we propose <strong>Abductive Latent Explanations (ALEs)</strong>, a formalism to express sufficient conditions on the intermediate (latent) representation of the instance that imply the prediction.
            </p>
            <p>
              Our approach combines the inherent interpretability of case-based reasoning models and the guarantees provided by formal XAI. We propose a solver-free and scalable algorithm for generating ALEs based on three distinct paradigms, compare them, and present the feasibility of our approach on diverse datasets for both standard and fine-grained image classification.
            </p>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="hero is-small">
    <div class="hero-body">
      <div class="container">
        <h2 class="title is-3 has-text-centered">Methodology & Results</h2>
        <div id="results-carousel" class="carousel results-carousel">
          <div class="item">
            <img src="static/images/method_diagram.png" alt="Methodology Diagram" />
            <h2 class="subtitle has-text-centered">ALE Construction Framework</h2>
          </div>
          <div class="item">
             <img src="static/images/results_table.png" alt="Table 2 Results" />
            <h2 class="subtitle has-text-centered">Summary of Average Explanation Sizes</h2>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <div class="bibtex-header">
        <h2 class="title">BibTeX</h2>
        <button class="copy-bibtex-btn" onclick="copyBibTeX()" title="Copy BibTeX to clipboard">
          <i class="fas fa-copy"></i>
          <span class="copy-text">Copy</span>
        </button>
      </div>
      <pre id="bibtex-code"><code>@inproceedings{Soria2026Formal,
  title={Formal Abductive Latent Explanations for Prototype-Based Networks},
  author={Soria, Jules and Chihani, Zakaria and Girard-Satabin, Julien and Grastien, Alban and Xu-Darme, Romain and Cancila, Daniela},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  year={2026},
  url={https://github.com/julsoria/ale}
}</code></pre>
    </div>
  </section>

  <footer class="footer">
    <div class="container">
      <div class="content has-text-centered">
        <p>
          This website is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">Creative Commons Attribution-ShareAlike 4.0 International License</a>.
          Source code based on <a href="https://nerfies.github.io">Nerfies</a>.
        </p>
      </div>
    </div>
  </footer>

</body>
</html>