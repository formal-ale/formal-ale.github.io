<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <meta name="title" content="Formal Abductive Latent Explanations for Prototype-Based Networks">
  <meta name="description" content="We propose Abductive Latent Explanations (ALEs), a formalism to express sufficient conditions on the intermediate representation of an instance that imply the prediction.">
  <meta name="keywords" content="Explainable AI, Prototype-based Networks, Abductive Reasoning, Formal Verification, Machine Learning, Computer Vision">
  <meta name="author" content="Jules Soria, Zakaria Chihani, Julien Girard-Satabin, Alban Grastien, Romain Xu-Darme, Daniela Cancila">
  <meta name="robots" content="index, follow">
  <meta name="language" content="English">
  
  <meta property="og:type" content="article">
  <meta property="og:site_name" content="Universit√© Paris-Saclay, CEA, List">
  <meta property="og:title" content="Formal Abductive Latent Explanations for Prototype-Based Networks">
  <meta property="og:description" content="We propose Abductive Latent Explanations (ALEs), a formalism to express sufficient conditions on the intermediate representation of an instance that imply the prediction.">
  <meta property="og:url" content="https://julsoria.github.io/ale/"> 
  <meta property="og:image" content="static/images/figure1_preview.png">
  <meta property="og:image:width" content="1200">
  <meta property="og:image:height" content="630">
  <meta property="og:image:alt" content="ALE Framework Overview">

  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:title" content="Formal Abductive Latent Explanations for Prototype-Based Networks">
  <meta name="twitter:description" content="Bridging the gap between FXAI and prototype-based learning with formal guarantees.">
  <meta name="twitter:image" content="static/images/figure1_preview.png">

  <meta name="citation_title" content="Formal Abductive Latent Explanations for Prototype-Based Networks">
  <meta name="citation_author" content="Soria, Jules">
  <meta name="citation_author" content="Chihani, Zakaria">
  <meta name="citation_author" content="Girard-Satabin, Julien">
  <meta name="citation_author" content="Grastien, Alban">
  <meta name="citation_author" content="Xu-Darme, Romain">
  <meta name="citation_author" content="Cancila, Daniela">
  <meta name="citation_publication_date" content="2026">
  <meta name="citation_conference_title" content="AAAI Conference on Artificial Intelligence">
  
  <title>Formal Abductive Latent Explanations for Prototype-Based Networks</title>
  
  <!-- <link rel="icon" type="image/x-icon" href="static/images/favicon.ico"> -->
  <link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üç∫</text></svg>">
  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/index.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700;800&display=swap" rel="stylesheet">
  
  <script defer src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script defer src="static/js/bulma-carousel.min.js"></script>
  <script defer src="static/js/bulma-slider.min.js"></script>
  <script defer src="static/js/index.js"></script>
  
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "ScholarlyArticle",
    "headline": "Formal Abductive Latent Explanations for Prototype-Based Networks",
    "author": [
      {"@type": "Person", "name": "Jules Soria"},
      {"@type": "Person", "name": "Zakaria Chihani"},
      {"@type": "Person", "name": "Julien Girard-Satabin"},
      {"@type": "Person", "name": "Alban Grastien"},
      {"@type": "Person", "name": "Romain Xu-Darme"},
      {"@type": "Person", "name": "Daniela Cancila"}
    ],
    "datePublished": "2026-01-01",
    "publisher": {"@type": "Organization", "name": "AAAI"},
    "keywords": ["XAI", "Formal Methods", "Prototype Networks", "Abductive Explanations"]
  }
  </script>
  <script>
  MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']],
      displayMath: [['$$', '$$'], ['\\[', '\\]']],
      processEscapes: true
    }
  };
  </script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>
<body>

  <main id="main-content">
  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Formal Abductive Latent Explanations<br>for Prototype-Based Networks</h1>
            
            <div class="is-size-5 publication-authors">
              
              <span class="author-block">
                <a href="https://scholar.google.com/citations?user=1Qctec0AAAAJ" target="_blank" class="has-text-primary">
                  <strong>Jules Soria</strong>
                </a>
                <span class="icon is-small" style="vertical-align: super; font-size: 0.6em;" title="Corresponding Author">
                  <i class="fas fa-envelope"></i>
                </span>,
              </span>

              <span class="author-block">
                <a href="https://scholar.google.com/citations?user=mgzCh30AAAAJ" target="_blank">
                  Zakaria Chihani
                </a>,
              </span>
              <span class="author-block">
                <a href="https://scholar.google.com/citations?user=erWN5TwAAAAJ" target="_blank">
                  Julien Girard-Satabin
                </a>,
              </span>
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <a href="https://scholar.google.com/citations?user=87u0x6UAAAAJ" target="_blank">
                  Alban Grastien
                </a>,
              </span>
              <span class="author-block">
                <a href="https://scholar.google.com/citations?user=QB4YkI0AAAAJ" target="_blank">
                  Romain Xu-Darme
                </a>,
              </span>
              <span class="author-block">
                <a href="https://scholar.google.com/citations?user=ucNJ23sAAAAJ" target="_blank">
                  Daniela Cancila
                </a>
              </span>
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block">Universit√© Paris-Saclay, CEA, List, F-91120, Palaiseau, France</span>
            </div>

            <div class="is-size-5 publication-authors" style="margin-top: 10px; font-weight: bold;">
              <span class="author-block">AAAI 2026</span>
            </div>

            <div class="column has-text-centered">
              <div class="publication-links">
                <span class="link-block">
                  <a href="static/pdfs/paper.pdf" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon"><i class="fas fa-file-pdf"></i></span>
                  <span>Paper</span>
                  </a>
                </span>

                <span class="link-block">
                  <a href="https://github.com/julsoria/ale" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon"><i class="fab fa-github"></i></span>
                  <span>Code</span>
                  </a>
                </span>

                <span class="link-block">
                  <a href="https://arxiv.org/" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon"><i class="ai ai-arxiv"></i></span>
                  <span>arXiv</span>
                  </a>
                </span>

                <span class="link-block">
                  <a href="https://zenodo.org/" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon"><i class="ai ai-zenodo"></i></span>
                  <span>Zenodo</span>
                  </a>
                </span>
                
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="hero teaser">
    <div class="container is-max-desktop">
      <div class="hero-body">
        <div class="has-text-centered">
            <img src="static/images/figure1_teaser.png" 
                 alt="Figure 1: Example of a top-1 explanation for a ProtoPNet"
                 style="width: 100%; height: auto; max-width: 1000px; border-radius: 10px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);">
        </div>
        <h2 class="subtitle has-text-centered" style="margin-top: 15px;">
          <strong>Figure 1:</strong> Example of a top-$1$ explanation for a ProtoPNet with five prototypical parts for two classes.
          We propose <strong>ALEs</strong> to bridge the gap between Formal XAI and prototype-based learning.
        </h2>
      </div>
    </div>
  </section>

  <section class="section hero is-light">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <p>
              Case-based reasoning networks are machine-learning models that make predictions based on similarity between the input and prototypical parts of training samples, called prototypes. Such models are able to explain each decision by pointing to the prototypes that contributed the most to the final outcome. As the explanation is a core part of the prediction, they are often qualified as "interpretable by design".
            </p>
            <p>
              While promising, we show that such explanations are sometimes misleading, which hampers their usefulness in safety-critical contexts. In particular, several instances may lead to different predictions and yet have the same explanation. Drawing inspiration from the field of formal eXplainable AI (FXAI), we propose <strong>Abductive Latent Explanations (ALEs)</strong>, a formalism to express sufficient conditions on the intermediate (latent) representation of the instance that imply the prediction.
            </p>
            <p>
              Our approach combines the inherent interpretability of case-based reasoning models and the guarantees provided by formal XAI. We propose a solver-free and scalable algorithm for generating ALEs based on three distinct paradigms, compare them, and present the feasibility of our approach on diverse datasets for both standard and fine-grained image classification.
            </p>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="section" style="background-color: #f5f5f5;">
  <div class="container is-max-desktop">
    
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Methodology: Formal Abduction in Latent Space</h2>
        <div class="content has-text-justified">
          <p>
            We propose a framework to generate <strong>Abductive Latent Explanations (ALEs)</strong>. 
            Unlike pixel-based methods which are often NP-complete, our approach operates on the latent manifold $\mathcal{Z}$, 
            leveraging the fixed positions of prototypes to generate solver-free guarantees.
          </p>
        </div>
      </div>
    </div>

    <div class="columns is-centered">
      
      <div class="column is-6">
        <div class="box" style="height: 100%;">
          <h4 class="title is-5 has-text-centered">1. Formal Definition (ALE)</h4>
          <div class="content">
            <p>
              Given an input $v$ and a predictor $\kappa$, an ALE is a subset of latent features $\mathcal{E} \subseteq P \times L$ 
              that entails a precondition $\phi_{\mathcal{E}}$ satisfied by the input. The explanation is valid if it logically entails the prediction $c$:
            </p>
            $$
            \forall x \in \mathcal{F}, \quad \phi_{\mathcal{E}}(f(x), f(v)) \Rightarrow (\kappa(x) = c)
            $$
            <p>
              We specifically seek <strong>subset-minimal</strong> explanations, ensuring that removing any single feature-prototype pair 
              $(z_l, p_j)$ from $\mathcal{E}$ breaks the sufficiency guarantee.
            </p>
          </div>
        </div>
      </div>

      <div class="column is-6">
        <div class="box" style="height: 100%;">
          <h4 class="title is-5 has-text-centered">2. Verification via Class Domination</h4>
          <div class="content">
            <p>
              To verify an explanation without a solver, we construct the <strong>Maximally Class-Favoring Element</strong> $a^*$. 
              We verify if the predicted class $c$ dominates an alternative class $k$ even under the worst-case bounds:
            </p>
            $$
            h_k(a_{\mathcal{E}}^*(k,c)) - h_c(a_{\mathcal{E}}^*(k,c)) \le 0
            $$
            <p>
              If this holds for all $k \neq c$, the explanation is formally verified (Theorem 2). This turns the verification problem 
              into a polynomial-time check rather than an expensive logical search.
            </p>
          </div>
        </div>
      </div>
    </div>

    <div class="columns is-centered mt-4">
      <div class="column is-10">
        <div class="message is-info">
          <div class="message-header">
            <p>Bounding Mechanism: Hypersphere Intersection Approximation</p>
          </div>
          <div class="message-body has-text-centered">
            <p class="mb-4 has-text-justified">
              A key contribution is reducing the search space using geometry. We model the latent vector location as the intersection of hyperspheres. 
              Let $H_1, H_2$ be hyperspheres with centers $C_1, C_2$ and radii $r_1, r_2$. The approximating hypersphere $H_3$ is defined by:
            </p>
            
            $$
            \begin{align}
            r_3 &= \frac{2}{d}\sqrt{p(p-d)(p-r_1)(p-r_2)} \\
            C_3 &= C_1 + \sqrt{r_1^2 - r_3^2} \cdot \frac{C_2 - C_1}{d}
            \end{align}
            $$
            
            <p class="mt-4 has-text-justified is-size-7">
              Where $d = ||C_1 - C_2||_2$ is the distance between centers and $p = \frac{1}{2}(d+r_1+r_2)$ is the semi-perimeter.
              <strong>Theorem 1</strong> guarantees that $H_3$ is the smallest possible hypersphere containing the intersection, ensuring valid and tight constraints for the ALE.
            </p>
          </div>
        </div>
      </div>
    </div>

  </div>
  </section>

  
  <section class="section" style="background-color: #f5f5f5;">
  <div class="container is-max-desktop">
    <h2 class="title is-3 has-text-centered">Visualizing the Latent Bounds</h2>
    <div class="content has-text-centered">
      <p>
        To certify an explanation without a solver, we must bound the location of the latent vector $z$.
        We compare our two paradigms below. The <strong>Hypersphere Intersection</strong> (Right) yields potentially 
        tighter bounds (blue dashed line) than the <strong>Triangle Inequality</strong> (Center), approximating the 
        true distances (Left) more accurately.
      </p>
    </div>

    <div class="columns is-centered">
      
      <div class="column is-4 has-text-centered">
        <figure class="image is-inline-block">
          <img src="static/images/geometric_figure_true.png" 
               alt="True Distances Ground Truth" 
               style="height: 300px; object-fit: contain; width: auto; border: 1px solid #bbb; border-radius: 5px; background: white;">
        </figure>
        <h4 class="subtitle is-6 mt-2">
          Ground Truth
        </h4>
        <p class="is-size-7">
          True distances $d(P, z)$ and $d(P, z')$ in the latent space.<br>
          <em>Ref: 0.846 | 1.364</em>
        </p>
      </div>

      <div class="column is-4 has-text-centered">
        <figure class="image is-inline-block">
          <img src="static/images/geometric_figure_triangle.png" 
               alt="Triangle Inequality Bounds" 
               style="height: 300px; object-fit: contain; width: auto; border: 1px solid #bbb; border-radius: 5px; background: white;">
        </figure>
        <h4 class="subtitle is-6 mt-2">
          <strong>Paradigm 1:</strong><br>Triangle Inequality
        </h4>
        <p class="is-size-7">
          Loose bounds derived from distances between prototypes.<br>
          <em>Range: [0.656, 1.600]</em>
        </p>
      </div>

      <div class="column is-4 has-text-centered">
        <figure class="image is-inline-block">
          <img src="static/images/geometric_figure_intersection.png" 
               alt="Hypersphere Intersection Bounds"
               style="height: 300px; object-fit: contain; width: auto; border: 1px solid #bbb; border-radius: 5px; background: white;">
        </figure>
        <h4 class="subtitle is-6 mt-2">
          <strong>Paradigm 2:</strong><br>Hypersphere Intersection
        </h4>
        <p class="is-size-7">
          Tighter bounds by intersecting constraints.<br>
          <em>Range: [0.839, 1.368]</em>
        </p>
      </div>

    </div>
  </div>
</section>

  <section class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-3 has-text-centered">Experimental Results</h2>
    <div class="content has-text-justified">
      <p>
        We evaluated our approach on diverse datasets (CIFAR-10, MNIST, Oxford Flowers, etc.). 
        The table below summarizes the average explanation sizes. Note that Spatial ALEs 
        frequently yields more compact explanations or tighter bounds compared to the top-$k$ heuristic.
      </p>
    </div>

    <div class="box">
      <figure class="image is-fullwidth">
        <img src="static/images/results_table.png" alt="Table 2: Summary of Average Explanation Sizes">
        <figcaption class="has-text-centered is-size-7 mt-2">
          <strong>Table 2:</strong> Summary of Average Explanation Sizes (Correct / Incorrect) for each dataset. 
          Best (smallest) results indicated in bold.
        </figcaption>
      </figure>
    </div>
  </div>
  </section>

  <section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Framework</h2>
        <div class="content has-text-justified">
          <p>
            Our models were trained using <strong>CaBRNet</strong> (Case-Based Reasoning Network), 
            an open-source library designed for developing and evaluating prototype-based models. 
            <!-- CaBRNet ensures that the underlying prototype layers and decision mechanisms adhere 
            strictly to the interpretable-by-design philosophy required for valid Abductive Latent Explanations. -->
          </p>
          <div class="has-text-centered">
            <a href="https://github.com/aiser-team/cabrnet" target="_blank" class="button is-dark is-rounded">
              <span class="icon"><i class="fab fa-github"></i></span>
              <span>View CaBRNet Repository</span>
            </a>
          </div>
        </div>
      </div>
    </div>
  </div>
  </section>

  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <div class="bibtex-header">
        <h2 class="title">BibTeX</h2>
        <button class="copy-bibtex-btn" onclick="copyBibTeX()" title="Copy BibTeX to clipboard">
          <i class="fas fa-copy"></i>
          <span class="copy-text">Copy</span>
        </button>
      </div>
      <pre>Coming soon!</pre>
      <!-- <pre id="bibtex-code"><code>@inproceedings{soria2026formal,
  title={Formal Abductive Latent Explanations for Prototype-Based Networks},
  author={Soria, Jules and Chihani, Zakaria and Girard-Satabin, Julien and Grastien, Alban and Xu-Darme, Romain and Cancila, Daniela},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  year={2026},
  url={https://github.com/julsoria/ale}
}</code></pre> -->
    </div>
  </section>

  <section class="section" id="Acknowledgements">
  <div class="container is-max-desktop content">
    <h2 class="title">Acknowledgements</h2>
    <p>
      This publication was made possible by the use of the <strong>FactoryIA supercomputer</strong>, financially supported by the Ile-De-France Regional Council.
      This work was also supported by the <strong>SAIF project</strong>, funded by the "France 2030" government investment plan managed by the French National Research Agency, under the reference <strong>ANR-23-PEIA-0006</strong>.
    </p>
  </div>
  </section>

  


  <footer class="footer">
    <div class="container">
      <div class="content has-text-centered">
        <p>
          This website is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">Creative Commons Attribution-ShareAlike 4.0 International License</a>.
          Source code based on <a href="https://nerfies.github.io">Nerfies</a>.
        </p>
      </div>
    </div>
  </footer>

</body>
</html>